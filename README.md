# Multimodal Analysis of Infant Crying

## 环境配置
- **Python版本**: 3.10.15
- **PyTorch版本**: 1.13.1
- **TensorFlow版本**: 2.10.0

## 数据处理(data.py)
- **音频增强策略**: 采取音频增强技术对音频数据进行处理。
- **音频分割**: 将音频文件分割为10秒的数据（对于不足10秒的数据，将会被扩充至10秒）。
- **STFT转换**: 使用短时傅里叶变换（STFT）将音频转化为频谱图，作为输入数据送入模型进行计算。
- **标签处理**: 保留分类好的标签，确保模型按照既定标签进行音频数据分类。

## 模型部分(model.py)
- **网络结构**: 使用CNN + DNN的组合网络结构。
- **CNN部分**:
  - 4个卷积层。
  - 使用Dropout层，随机丢弃50%的神经元，以避免过拟合。
- **DNN部分**:
  - 2个全连接层。
  - 最后输出层的输出维度为 `n_classes`，即分类任务中的类别数。
- **激活函数**: 使用ReLU激活函数。
- **损失函数**: 使用交叉熵损失函数（CrossEntropyLoss）。

## 优化器配置(model.py)
使用Adam优化器，配置如下：
```python
optimizer = optim.Adam(
    model.parameters(),
    lr=0.001,            # 学习率
    betas=(0.9, 0.999),  # beta1, beta2
    eps=1e-7,            # epsilon
    weight_decay=1e-5,   # L2正则化
    amsgrad=False        # 是否使用AMSGrad
)
```

## 学习率调度与早期停止(train.py)
- **学习率调度**: 使用CosineAnnealingLR学习率调度器。
- **早期停止策略**: 采用早期停止策略，防止过拟合。

## 训练过程(train.py)
- **训练与验证曲线**: 记录并绘制训练和验证过程中的损失曲线、准确率曲线、学习率曲线。
- **模型评估**:
    - 使用混淆矩阵进行模型评估。
    - 使用准确率评估模型性能。
- **模型保存**:保存训练好的模型和标签编码，以便后续使用或部署。

## 推理分类（trst.py）
- 使用已经学习好的模型数据对于未知的音频文件进行分类推理